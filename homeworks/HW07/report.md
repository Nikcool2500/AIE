# HW07 – Report

> Файл: `homeworks/HW07/report.md`
> (заполнено по шаблону)

## 1. Datasets

Выбраны 3 датасета: `S07-hw-dataset-01.csv`, `S07-hw-dataset-02.csv`, `S07-hw-dataset-03.csv`.

### 1.1 Dataset A

* Файл: `S07-hw-dataset-01.csv`
* Размер: (12000, 8)
* Признаки: все числовые — `['f01','f02','f03','f04','f05','f06','f07','f08']`
* Пропуски: отсутствуют (по результатам предварительного анализа в ноутбуке)
* "Подлости" датасета: признаки в разных шкалах, присутствуют шумовые признаки (требуется масштабирование).

### 1.2 Dataset B

* Файл: `S07-hw-dataset-02.csv`
* Размер: (8000, 3)
* Признаки: все числовые — `['x1','x2','z_noise']`
* Пропуски: отсутствуют
* "Подлости" датасета: нелинейная структура + выбросы + лишний шумовой признак (`z_noise`) — плохо подходит для KMeans без дополнительных приёмов.

### 1.3 Dataset C

* Файл: `S07-hw-dataset-03.csv`
* Размер: (15000, 4)
* Признаки: все числовые — `['x1','x2','f_corr','f_noise']`
* Пропуски: отсутствуют
* "Подлости" датасета: кластеры разной плотности и фоновой шум — DBSCAN чувствителен к `eps`.

## 2. Protocol

* **Препроцессинг:** для всех датасетов использован единый протокол: `SimpleImputer(strategy='median')` (если есть пропуски) + `StandardScaler` для числовых признаков. Если бы были категориальные признаки — использовали бы `OneHotEncoder(handle_unknown="ignore")`. Реализация через `Pipeline`/`ColumnTransformer`.
* **Поиск гиперпараметров:**

  * KMeans: диапазон `k = 2..12`. `random_state` фиксирован (42), `n_init=10`. Лучшее `k` выбран по максимуму `silhouette_score`.
  * DBSCAN: кандидаты `eps` строились на основе квантилей попарных расстояний (k-distance / percentiles), `min_samples` в наборе {3,5,8}. Лучший выбор — по `silhouette_score` на непомеченных как шум точках.
* **Критерий выбора "лучшего":** при автоматическом подборе использовали `silhouette` как основной ориентиp (для компактности кластеров) с просмотром `davies_bouldin` и `calinski_harabasz` для дополнительной оценки и интерпретации. Для DBSCAN дополнительно фиксировали долю шума (`n_noise`, `noise_fraction`) и учитывали влияние на CH.
* **Метрики:** считались `silhouette_score` (выше — лучше), `davies_bouldin_score` (ниже — лучше), `calinski_harabasz_score` (выше — лучше). Для DBSCAN метрики рассчитывались на non-noise точках (label != -1); при выводе указывается доля шума.
* **Визуализация:** PCA(2D) для всех датасетов (в отчёте предполагается вставить `artifacts/figures/ds*_pca_best.png`). t-SNE не использовался (опционально).

## 3. Models

На каждом датасете сравнивались:

* **KMeans** — подбор `k` в диапазоне 2..12; фиксированы `random_state=42`, `n_init=10`.
* **DBSCAN** — подбор `eps` (кандидаты по квантилям попарных расстояний) и `min_samples` ∈ {3,5,8}. Сохранялись доля и число шумовых точек.

(Агломеративная кластеризация не использовалась в финальном сравнении, но возможна как дополнительный метод.)

## 4. Results

(Все числовые значения взяты из `artifacts/metrics_summary.json`.)

### 4.1 Dataset A

* Лучший метод и параметры: **KMeans** `k = 2` (в `best_configs.json`), DBSCAN нашёл аналогичное разбиение при `eps = 1.6816959596576166`, `min_samples = 3`.
* Метрики (KMeans / DBSCAN одинаковы):

  * silhouette = **0.52164**
  * Davies–Bouldin = **0.68533**
  * Calinski–Harabasz = **11786.95**
* Если был DBSCAN: `n_noise = 0`, `noise_fraction = 0.0`.
* Почему разумно: высокая silhouette и низкий DB указывают на компактные, хорошо отделённые кластеры; DBSCAN повторил результат — структура близка к сферической/равномерной, что оправдывает KMeans.

### 4.2 Dataset B

* Лучший метод и параметры: **DBSCAN** `eps = 0.7547388931955843`, `min_samples = 8` (выбран как лучший по silhouette).
* Метрики:

  * KMeans (k=2): silhouette = **0.30686**, Davies–Bouldin = **1.32347**, CH = **3573.39**.
  * DBSCAN: silhouette = **0.41650**, Davies–Bouldin = **0.61980**, CH = **57.28**, `n_noise = 100` (`noise_fraction = 0.0125`).
* Комментарий по шуму: DBSCAN пометил ~1.25% точек как шум — это помогло улучшить silhouette и DB, но CH снизился (логично: уменьшилось число «активных» точек и межкластерная дисперсия).
* Почему разумно: нелинейная геометрия и выбросы — сильный аргумент в пользу плотностного метода (DBSCAN).

### 4.3 Dataset C

* Лучший метод и параметры: **KMeans** `k = 3` (практичный выбор); DBSCAN: `eps = 0.6829379747226404`, `min_samples = 3`.
* Метрики:

  * KMeans (k=3): silhouette = **0.31554**, Davies–Bouldin = **1.15773**, CH = **6957.16**.
  * DBSCAN: silhouette = **0.23179**, Davies–Bouldin = **0.59654**, CH = **12.87**, `n_noise = 50` (`noise_fraction ≈ 0.00333`).
* Комментарий: метрики конфликтуют (DB лучше по DB, но хуже по silhouette и CH). Переменная плотность кластеров делает DBSCAN чувствительным к `eps`. KMeans (k=3) выбран как более интерпретируемый/практичный вариант для фиксированного числа групп.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

* **Где KMeans "ломается":** при нелинейных формах кластеров и при наличии выбросов/шумовых признаков (пример — ds2): KMeans предполагает шарообразные кластеры и вырождается на сложной геометрии.
* **Где DBSCAN выигрывает:** на нелинейных плотностных структурах и при наличии отдельных выбросов; DBSCAN автоматически выделяет шум и локальные плотные группы.
* **Главные факторы влияния:** масштабирование (обязательное для distance-based методов), выбросы и вариативность плотности, наличие шумовых признаков. Пропуски в этих датасетах отсутствовали; категориальных признаков не было.

### 5.2 Устойчивость (обязательно для одного датасета)

* Проверка: KMeans на `ds1` — 5 запусков с random_state = [1,7,13,21,99] при `k=2`. Оценка — парные ARI.
* Результат: парные ARI = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]; ARI mean = **1.0000**, min = **1.0000**, max = **1.0000**. (Артефакт: `artifacts/stability_ds1_ari.json`.)
* Вывод: разбиение KMeans для ds1 абсолютно детерминировано при выбранных параметрах/инициализациях — высокая устойчивость (ARI = 1).

### 5.3 Интерпретация кластеров

* Подход: для каждого лучшего решения рекомендовано смотреть PCA(2D) scatter и профили признаков (mean/median per cluster).
* Краткие выводы:

  * ds1: два явных профиля признаков — кластеры симметричны и компактны (KMeans хорош).
  * ds2: PCA-визуализация показывает, что DBSCAN выделяет один доминирующий кластер и один очень небольшой кластер, который визуально почти сливается с шумом. Малый кластер не образует чётко отделённой плотной области и выглядит как флуктуация плотности, а не полноценная группа. Это указывает на ограниченную интерпретируемость результата DBSCAN для данного датасета.
  * ds3: кластеры интерпретируются с трудом: различия между ними невелики, распределения признаков существенно перекрываются. Разбиение носит скорее формальный характер и не отражает чётко выраженные группы объектов.

## 6. Conclusion

1. Всегда масштабируйте числовые признаки перед применением distance-based методов — без этого результаты могут быть сильно искажены.
2. KMeans хорошо работает при примерно шарообразных, равномерно плотных кластерах; DBSCAN — при сложной нелинейной геометрии и при наличии выбросов.
3. Внутренние метрики (silhouette/DB/CH) иногда конфликтуют — используйте их в связке и учитывайте долю шума/размеры кластеров при интерпретации.
4. Для DBSCAN подбор `eps` критичен; k-distance plot и квантильный подход к кандидатам eps помогают.
5. Устойчивость — важный шаг: ARI между запусками (или на подвыборках) показывает, насколько надежно алгоритм выдаёт разбиение.
6. Для практического применения рекомендуется сохранять метки (CSV) и изображения PCA/tuning в `artifacts/` — это облегчает верификацию и предоставление результатов.
7. В дальнейшей работе можно добавить AgglomerativeClustering и глубокий grid для DBSCAN (k-distance с визуализацией), t-SNE для визуализации локальной структуры.
8. Итог: протокол (eda→preproc→grid→metrics→pca→stability) даёт воспроизводимые и объяснимые результаты на синтетических датасетах.
