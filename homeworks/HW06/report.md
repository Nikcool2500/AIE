# HW06 – Report

## 1. Dataset

- **Датасет**: `S06-hw-dataset-04.csv`
- **Размер**: 25 000 строк, 62 столбца (60 признаков + `id` + `target`)
- **Целевая переменная**: `target` (бинарная: 0 — 95.08%, 1 — 4.92%). Наблюдается сильный дисбаланс классов.
- **Признаки**: Все 60 признаков (`f01`–`f60`) — числовые (тип `float64`). Пропущенных значений нет. Данные имеют разный масштаб, поэтому применена стандартизация для линейных моделей.

## 2. Protocol

- **Разбиение**: Стратифицированное разделение на train/test в пропорции 80/20 (`test_size=0.2`) с фиксированным `random_state=42`.  
  Train: 20 000 объектов, test: 5 000 объектов.
- **Подбор гиперпараметров**: Для DecisionTree, RandomForest и HistGradientBoosting использован `GridSearchCV` с `StratifiedKFold`:
  - DecisionTree: 5 фолдов, оптимизация по ROC‑AUC.
  - RandomForest и HistGradientBoosting: 3 фолда (для экономии времени), оптимизация по ROC‑AUC.
- **Метрики**:
  - **Accuracy** — общая точность, но может быть завышена из‑за дисбаланса.
  - **F1‑score** — баланс между precision и recall, важна для миноритарного класса.
  - **ROC‑AUC** — устойчива к дисбалансу, оценивает способность модели разделять классы.
  - **Average Precision** — площадь под PR‑кривой, актуальна при сильном дисбалансе.

## 3. Models

1. **DummyClassifier (baseline)**: `strategy='most_frequent'` — предсказывает самый частый класс.
2. **LogisticRegression**: Паплайн с `StandardScaler` и балансировкой классов (`class_weight='balanced'`).
3. **DecisionTreeClassifier**: Подбор `max_depth`, `min_samples_split`, `min_samples_leaf`, `class_weight` (сетка из 120 комбинаций).
4. **RandomForestClassifier**: Подбор `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `class_weight`, `max_features` (324 комбинации).
5. **HistGradientBoostingClassifier**: Подбор `max_iter`, `max_depth`, `learning_rate`, `min_samples_leaf`, `l2_regularization`, `max_bins` (324 комбинации).
6. **StackingClassifier** (опционально): Базовые модели — DecisionTree, RandomForest, HistGradientBoosting (с фиксированными параметрами), мета‑модель — LogisticRegression. CV‑стекинг с 3 фолдами.

## 4. Results

| Модель                  | Accuracy | F1       | ROC‑AUC  | Avg Precision |
|-------------------------|----------|----------|----------|---------------|
| Stacking                | 0.9424   | 0.5765   | 0.9015   | 0.7843        |
| RandomForest            | 0.9724   | 0.6102   | 0.8940   | 0.7934        |
| HistGradientBoosting    | 0.9784   | 0.7245   | 0.8904   | 0.7745        |
| LogisticRegression      | 0.7756   | 0.2540   | 0.8355   | 0.4582        |
| DecisionTree            | 0.8798   | 0.3746   | 0.8277   | 0.3272        |
| DummyClassifier         | 0.9508   | 0.0000   | 0.5000   | 0.0492        |

**Победитель**:  
По основной метрике (ROC‑AUC) лучший результат показал **StackingClassifier** (0.9015). Однако HistGradientBoosting имеет наибольший F1‑score (0.7245), что важно для задачи с дисбалансом.

## 5. Analysis

- **Устойчивость**: В ноутбуке не проводилось многократное изменение `random_state`. Для проверки можно выполнить 5 прогонов для RandomForest и HistGradientBoosting. Ожидаемо, что метрики будут колебаться незначительно благодаря большому объёму данных и стратификации.
- **Ошибки**: Confusion matrix для StackingClassifier (на test):
  ```
  [[4740   44]
   [ 244   32]]
  ```
  Precision для класса 1: 0.421, Recall: 0.116. Модель плохо обнаруживает миноритарный класс (низкий recall), но precision приемлемый.
- **Интерпретация**: Permutation importance (StackingClassifier, top‑15 признаков):
  1. `f52` (важность ≈ 0.14)
  2. `f57` (≈ 0.10)
  3. `f04` (≈ 0.08)
  4. `f07` (≈ 0.07)
  5. `f08` (≈ 0.06)
  6. `f58` (≈ 0.05)
  7. `f54` (≈ 0.04)
  8. `f53` (≈ 0.03)
  9. `f01` (≈ 0.02)
  10. `f02` (≈ 0.02)
  Остальные признаки имеют важность <0.02.  
  Вывод: Наиболее информативны признаки `f52`, `f57`, `f04`. Возможно, остальные можно исключить для упрощения модели.

## 6. Conclusion

1. **Дисбаланс классов** требует использования метрик, устойчивых к нему (ROC‑AUC, F1, Average Precision), и методов балансировки (например, `class_weight='balanced'`).
2. **Ансамбли** (RandomForest, HistGradientBoosting) стабильно превосходят одиночные модели (DecisionTree, LogisticRegression) по всем метрикам, особенно по F1‑score.
3. **Стекинг** может незначительно улучшить ROC‑AUC, но его выигрыш не всегда оправдывает усложнение пайплайна.
4. **Подбор гиперпараметров** с кросс‑валидацией и стратификацией критически важен для достижения наилучшего качества моделей.
5. **Permutation importance** позволяет выделить наиболее значимые признаки (в данном случае `f52`, `f57`, `f04`), что может помочь в сокращении размерности данных без существенной потери качества.
6. **Протокол оценки** (фиксированный `random_state`, стратификация, отдельный test‑set) обеспечивает воспроизводимость и корректное сравнение моделей.